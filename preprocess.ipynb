{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text pre-processing\n",
    "## Combine review title and body\n",
    "Entire file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "INPUT_FILE = f'archive/reviews_to_batch.csv'\n",
    "\n",
    "all_df = pd.read_csv(INPUT_FILE)\n",
    "all_df['combined_text'] = all_df['review_title'] + '. ' + all_df['review_verbatim']\n",
    "all_df = all_df.drop(columns=['review_title','review_verbatim'])\n",
    "\n",
    "all_df['date'] = all_df['date'].apply(lambda x: datetime.strptime(x, r\"%d-%b-%y\").strftime(r\"%m/%d/%Y\"))\n",
    "all_df.to_csv(f'fixed_data_11-11-22.csv', quoting=csv.QUOTE_ALL, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Pieces of problematic files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "PART = 'dh'\n",
    "INPUT_FILE = f'problem_chunks/reviews_part_{PART}'\n",
    "df = pd.read_csv(INPUT_FILE, header=None)\n",
    "df.columns=[\"review_id\",\"review_title\",\"review_verbatim\",\"role\",\"status\",\"location\",\"date\",\"rating\"]\n",
    "df['combined_text'] = df['review_title'] + '. ' + df['review_verbatim']\n",
    "df = df.drop(columns=['review_title','review_verbatim'])\n",
    "df['date'] = df['date'].apply(lambda x: datetime.strptime(x, r\"%B %d, %Y\").strftime(r\"%m/%d/%Y\"))\n",
    "df.to_csv(f'problem_chunks/part_{PART}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/06/2022 19:22:43 - INFO - \t missing_keys: []\n",
      "11/06/2022 19:22:43 - INFO - \t unexpected_keys: []\n",
      "11/06/2022 19:22:43 - INFO - \t mismatched_keys: []\n",
      "11/06/2022 19:22:43 - INFO - \t error_msgs: []\n",
      "11/06/2022 19:22:43 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m changed_list \u001b[39m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m    \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs:\n\u001b[0;32m     17\u001b[0m       \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m          changed_list\u001b[39m.\u001b[39mappend(doc\u001b[39m.\u001b[39m_\u001b[39m.\u001b[39mresolved_text)\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\spacy\\language.py:1589\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[1;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[0;32m   1587\u001b[0m     \u001b[39mfor\u001b[39;00m pipe \u001b[39min\u001b[39;00m pipes:\n\u001b[0;32m   1588\u001b[0m         docs \u001b[39m=\u001b[39m pipe(docs)\n\u001b[1;32m-> 1589\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs:\n\u001b[0;32m   1590\u001b[0m     \u001b[39myield\u001b[39;00m doc\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\spacy\\util.py:1651\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[0;32m   1644\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1645\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipe\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1648\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   1649\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   1650\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1651\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1652\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\fastcoref\\spacy_component\\spacy_component.py:130\u001b[0m, in \u001b[0;36mFastCorefResolver.pipe\u001b[1;34m(self, stream, batch_size, resolve_text)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpipe\u001b[39m(\u001b[39mself\u001b[39m, stream, batch_size\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, resolve_text\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 130\u001b[0m     \u001b[39mfor\u001b[39;00m docs \u001b[39min\u001b[39;00m util\u001b[39m.\u001b[39mminibatch(stream, size\u001b[39m=\u001b[39mbatch_size):\n\u001b[0;32m    131\u001b[0m         preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoref_model\u001b[39m.\u001b[39mpredict(\n\u001b[0;32m    132\u001b[0m                 texts\u001b[39m=\u001b[39m[doc\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs],max_tokens_in_batch\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_tokens_in_batch)\n\u001b[0;32m    133\u001b[0m         \u001b[39mfor\u001b[39;00m idx,pred \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(preds):\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\spacy\\util.py:1600\u001b[0m, in \u001b[0;36mminibatch\u001b[1;34m(items, size)\u001b[0m\n\u001b[0;32m   1598\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1599\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(size_)\n\u001b[1;32m-> 1600\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(items, \u001b[39mint\u001b[39;49m(batch_size)))\n\u001b[0;32m   1601\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1602\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\spacy\\util.py:1651\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[0;32m   1644\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1645\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipe\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1648\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   1649\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   1650\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1651\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1652\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\spacy\\pipeline\\pipe.pyx:53\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\spacy\\util.py:1651\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[0;32m   1644\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1645\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipe\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1648\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   1649\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   1650\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1651\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1652\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:73\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\spacy\\util.py:1600\u001b[0m, in \u001b[0;36mminibatch\u001b[1;34m(items, size)\u001b[0m\n\u001b[0;32m   1598\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1599\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(size_)\n\u001b[1;32m-> 1600\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(items, \u001b[39mint\u001b[39;49m(batch_size)))\n\u001b[0;32m   1601\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1602\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\spacy\\util.py:1651\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[0;32m   1644\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1645\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipe\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1648\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   1649\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   1650\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1651\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1652\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:73\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\spacy\\util.py:1600\u001b[0m, in \u001b[0;36mminibatch\u001b[1;34m(items, size)\u001b[0m\n\u001b[0;32m   1598\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1599\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(size_)\n\u001b[1;32m-> 1600\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(items, \u001b[39mint\u001b[39;49m(batch_size)))\n\u001b[0;32m   1601\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1602\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\spacy\\language.py:1586\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1583\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiprocessing_pipe(texts, pipes, n_process, batch_size)\n\u001b[0;32m   1584\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1585\u001b[0m     \u001b[39m# if n_process == 1, no processes are forked.\u001b[39;00m\n\u001b[1;32m-> 1586\u001b[0m     docs \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_doc(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts)\n\u001b[0;32m   1587\u001b[0m     \u001b[39mfor\u001b[39;00m pipe \u001b[39min\u001b[39;00m pipes:\n\u001b[0;32m   1588\u001b[0m         docs \u001b[39m=\u001b[39m pipe(docs)\n",
      "File \u001b[1;32mc:\\Users\\house\\workspace\\CIS_568_DataMining\\CIS568_textProject\\review_venv\\lib\\site-packages\\spacy\\language.py:1108\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[1;34m(self, doc_like)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   1107\u001b[0m     \u001b[39mreturn\u001b[39;00m Doc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\u001b[39m.\u001b[39mfrom_bytes(doc_like)\n\u001b[1;32m-> 1108\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE1041\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(doc_like)))\n",
      "\u001b[1;31mValueError\u001b[0m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'float'>"
     ]
    }
   ],
   "source": [
    "from fastcoref import spacy_component\n",
    "import spacy\n",
    "\n",
    "review = df['combined_text']\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\", \"lemmatizer\", \"ner\", \"textcat\"])\n",
    "nlp.add_pipe(\"fastcoref\")\n",
    "\n",
    "docs = nlp.pipe(\n",
    "   review, \n",
    "   component_cfg={\"fastcoref\": {'resolve_text': True}}\n",
    ")\n",
    "\n",
    "changed_list = []\n",
    "try:\n",
    "   for doc in docs:\n",
    "      try:\n",
    "         changed_list.append(doc._.resolved_text)\n",
    "      except:\n",
    "         changed_list.append(\"ERROR\")\n",
    "except TypeError:\n",
    "   print(\"Type Error\")\n",
    "\n",
    "df['antecedents_replaced'] = changed_list\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to split each review into individual sentences\n",
    "Sentencizer from spaCy does basic rule-based sentence boundary detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_verbatim</th>\n",
       "      <th>role</th>\n",
       "      <th>status</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>antecedents_replaced</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you will be busy!</td>\n",
       "      <td>Micro managed to the T. Score cards for everyt...</td>\n",
       "      <td>Underwriting Analyst</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>September 26, 2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>you will be busy!. Micro managed to the T. Sco...</td>\n",
       "      <td>you will be busy!. Micro managed to the T. Sco...</td>\n",
       "      <td>[you will be busy!., Micro managed to the T. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Easy going</td>\n",
       "      <td>very easy going,easy jobs, very nice and fun p...</td>\n",
       "      <td>Mold Press Operator</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Polo, IL</td>\n",
       "      <td>September 26, 2019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Easy going. very easy going,easy jobs, very ni...</td>\n",
       "      <td>Easy going. very easy going,easy jobs, very ni...</td>\n",
       "      <td>[Easy going., very easy going,easy jobs, very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great place to work if you want to meet new pe...</td>\n",
       "      <td>My experience had a lot of ups and downs. Typi...</td>\n",
       "      <td>TELLER SUPERVISOR</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>September 26, 2019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Great place to work if you want to meet new pe...</td>\n",
       "      <td>Great place to work if you want to meet new pe...</td>\n",
       "      <td>[Great place to work if you want to meet new p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Na</td>\n",
       "      <td>Fast paced. Customer service. Universal banker...</td>\n",
       "      <td>Services Associate I</td>\n",
       "      <td>Current Employee</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "      <td>September 25, 2019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Na. Fast paced. Customer service. Universal ba...</td>\n",
       "      <td>Na. Fast paced. Customer service. Universal ba...</td>\n",
       "      <td>[Na., Fast paced., Customer service., Universa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was great</td>\n",
       "      <td>It was a great place to work a lot of advancem...</td>\n",
       "      <td>Customer Service Representative</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Columbus, OH</td>\n",
       "      <td>September 25, 2019</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It was great. It was a great place to work a l...</td>\n",
       "      <td>It was great. It was a great place to work a l...</td>\n",
       "      <td>[It was great., It was a great place to work a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review_title  \\\n",
       "0                                  you will be busy!   \n",
       "1                                         Easy going   \n",
       "2  Great place to work if you want to meet new pe...   \n",
       "3                                                 Na   \n",
       "4                                       It was great   \n",
       "\n",
       "                                     review_verbatim  \\\n",
       "0  Micro managed to the T. Score cards for everyt...   \n",
       "1  very easy going,easy jobs, very nice and fun p...   \n",
       "2  My experience had a lot of ups and downs. Typi...   \n",
       "3  Fast paced. Customer service. Universal banker...   \n",
       "4  It was a great place to work a lot of advancem...   \n",
       "\n",
       "                              role            status        location  \\\n",
       "0             Underwriting Analyst   Former Employee  Pittsburgh, PA   \n",
       "1              Mold Press Operator   Former Employee        Polo, IL   \n",
       "2                TELLER SUPERVISOR   Former Employee        Maryland   \n",
       "3             Services Associate I  Current Employee   Charlotte, NC   \n",
       "4  Customer Service Representative   Former Employee    Columbus, OH   \n",
       "\n",
       "                 date  rating  \\\n",
       "0  September 26, 2019     4.0   \n",
       "1  September 26, 2019     3.0   \n",
       "2  September 26, 2019     3.0   \n",
       "3  September 25, 2019     2.0   \n",
       "4  September 25, 2019     5.0   \n",
       "\n",
       "                                       combined_text  \\\n",
       "0  you will be busy!. Micro managed to the T. Sco...   \n",
       "1  Easy going. very easy going,easy jobs, very ni...   \n",
       "2  Great place to work if you want to meet new pe...   \n",
       "3  Na. Fast paced. Customer service. Universal ba...   \n",
       "4  It was great. It was a great place to work a l...   \n",
       "\n",
       "                                antecedents_replaced  \\\n",
       "0  you will be busy!. Micro managed to the T. Sco...   \n",
       "1  Easy going. very easy going,easy jobs, very ni...   \n",
       "2  Great place to work if you want to meet new pe...   \n",
       "3  Na. Fast paced. Customer service. Universal ba...   \n",
       "4  It was great. It was a great place to work a l...   \n",
       "\n",
       "                                           sentences  \n",
       "0  [you will be busy!., Micro managed to the T. S...  \n",
       "1  [Easy going., very easy going,easy jobs, very ...  \n",
       "2  [Great place to work if you want to meet new p...  \n",
       "3  [Na., Fast paced., Customer service., Universa...  \n",
       "4  [It was great., It was a great place to work a...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_nlp = spacy.load(\"en_core_web_sm\", exclude=[\"lemmatizer\", \"ner\", \"textcat\"])\n",
    "\n",
    "df[\"sentences\"] = df[\"antecedents_replaced\"].apply(lambda x: [sent.text for sent in simple_nlp(x).sents])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment from HuggingFace\n",
    "Need to connect to HuggingFace models such as Bert-base-multilingual-uncased-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_model = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# data = ['Good work life balance, but lower than average compensation','Work assignments are challenging and the organization as a whole shifted focus to advancing technology.']\n",
    "# sentiment_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_verbatim</th>\n",
       "      <th>role</th>\n",
       "      <th>status</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>antecedents_replaced</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you will be busy!</td>\n",
       "      <td>Micro managed to the T. Score cards for everyt...</td>\n",
       "      <td>Underwriting Analyst</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>September 26, 2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>you will be busy!. Micro managed to the T. Sco...</td>\n",
       "      <td>you will be busy!. Micro managed to the T. Sco...</td>\n",
       "      <td>[you will be busy!., Micro managed to the T. S...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.997491240501...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Easy going</td>\n",
       "      <td>very easy going,easy jobs, very nice and fun p...</td>\n",
       "      <td>Mold Press Operator</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Polo, IL</td>\n",
       "      <td>September 26, 2019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Easy going. very easy going,easy jobs, very ni...</td>\n",
       "      <td>Easy going. very easy going,easy jobs, very ni...</td>\n",
       "      <td>[Easy going., very easy going,easy jobs, very ...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.987976372241...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great place to work if you want to meet new pe...</td>\n",
       "      <td>My experience had a lot of ups and downs. Typi...</td>\n",
       "      <td>TELLER SUPERVISOR</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>September 26, 2019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Great place to work if you want to meet new pe...</td>\n",
       "      <td>Great place to work if you want to meet new pe...</td>\n",
       "      <td>[Great place to work if you want to meet new p...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.999869465827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Na</td>\n",
       "      <td>Fast paced. Customer service. Universal banker...</td>\n",
       "      <td>Services Associate I</td>\n",
       "      <td>Current Employee</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "      <td>September 25, 2019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Na. Fast paced. Customer service. Universal ba...</td>\n",
       "      <td>Na. Fast paced. Customer service. Universal ba...</td>\n",
       "      <td>[Na., Fast paced., Customer service., Universa...</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.994416475296...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was great</td>\n",
       "      <td>It was a great place to work a lot of advancem...</td>\n",
       "      <td>Customer Service Representative</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Columbus, OH</td>\n",
       "      <td>September 25, 2019</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It was great. It was a great place to work a l...</td>\n",
       "      <td>It was great. It was a great place to work a l...</td>\n",
       "      <td>[It was great., It was a great place to work a...</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.999874949455...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review_title  \\\n",
       "0                                  you will be busy!   \n",
       "1                                         Easy going   \n",
       "2  Great place to work if you want to meet new pe...   \n",
       "3                                                 Na   \n",
       "4                                       It was great   \n",
       "\n",
       "                                     review_verbatim  \\\n",
       "0  Micro managed to the T. Score cards for everyt...   \n",
       "1  very easy going,easy jobs, very nice and fun p...   \n",
       "2  My experience had a lot of ups and downs. Typi...   \n",
       "3  Fast paced. Customer service. Universal banker...   \n",
       "4  It was a great place to work a lot of advancem...   \n",
       "\n",
       "                              role            status        location  \\\n",
       "0             Underwriting Analyst   Former Employee  Pittsburgh, PA   \n",
       "1              Mold Press Operator   Former Employee        Polo, IL   \n",
       "2                TELLER SUPERVISOR   Former Employee        Maryland   \n",
       "3             Services Associate I  Current Employee   Charlotte, NC   \n",
       "4  Customer Service Representative   Former Employee    Columbus, OH   \n",
       "\n",
       "                 date  rating  \\\n",
       "0  September 26, 2019     4.0   \n",
       "1  September 26, 2019     3.0   \n",
       "2  September 26, 2019     3.0   \n",
       "3  September 25, 2019     2.0   \n",
       "4  September 25, 2019     5.0   \n",
       "\n",
       "                                       combined_text  \\\n",
       "0  you will be busy!. Micro managed to the T. Sco...   \n",
       "1  Easy going. very easy going,easy jobs, very ni...   \n",
       "2  Great place to work if you want to meet new pe...   \n",
       "3  Na. Fast paced. Customer service. Universal ba...   \n",
       "4  It was great. It was a great place to work a l...   \n",
       "\n",
       "                                antecedents_replaced  \\\n",
       "0  you will be busy!. Micro managed to the T. Sco...   \n",
       "1  Easy going. very easy going,easy jobs, very ni...   \n",
       "2  Great place to work if you want to meet new pe...   \n",
       "3  Na. Fast paced. Customer service. Universal ba...   \n",
       "4  It was great. It was a great place to work a l...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [you will be busy!., Micro managed to the T. S...   \n",
       "1  [Easy going., very easy going,easy jobs, very ...   \n",
       "2  [Great place to work if you want to meet new p...   \n",
       "3  [Na., Fast paced., Customer service., Universa...   \n",
       "4  [It was great., It was a great place to work a...   \n",
       "\n",
       "                                           sentiment  \n",
       "0  [{'label': 'NEGATIVE', 'score': 0.997491240501...  \n",
       "1  [{'label': 'POSITIVE', 'score': 0.987976372241...  \n",
       "2  [{'label': 'POSITIVE', 'score': 0.999869465827...  \n",
       "3  [{'label': 'NEGATIVE', 'score': 0.994416475296...  \n",
       "4  [{'label': 'POSITIVE', 'score': 0.999874949455...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now can I get a corresponding sentiment for each sentence?\n",
    "df[\"sentiment\"] = df[\"sentences\"].apply(lambda x: sentiment_model(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('review_post.csv', index=False)\n",
    "df.to_csv('review_post.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199 entries, 0 to 198\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   review_title          199 non-null    object \n",
      " 1   review_verbatim       199 non-null    object \n",
      " 2   role                  199 non-null    object \n",
      " 3   status                199 non-null    object \n",
      " 4   location              199 non-null    object \n",
      " 5   date                  199 non-null    object \n",
      " 6   rating                199 non-null    float64\n",
      " 7   combined_text         199 non-null    object \n",
      " 8   antecedents_replaced  199 non-null    object \n",
      " 9   sentences             199 non-null    object \n",
      " 10  sentiment             199 non-null    object \n",
      "dtypes: float64(1), object(10)\n",
      "memory usage: 350.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199 entries, 0 to 198\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   review_title          199 non-null    object \n",
      " 1   review_verbatim       199 non-null    object \n",
      " 2   role                  199 non-null    object \n",
      " 3   status                199 non-null    object \n",
      " 4   location              199 non-null    object \n",
      " 5   date                  199 non-null    object \n",
      " 6   rating                199 non-null    float16\n",
      " 7   combined_text         199 non-null    object \n",
      " 8   antecedents_replaced  199 non-null    object \n",
      " 9   sentences             199 non-null    object \n",
      " 10  sentiment             199 non-null    object \n",
      "dtypes: float16(1), object(10)\n",
      "memory usage: 349.3 KB\n"
     ]
    }
   ],
   "source": [
    "df['rating'] = df['rating'].astype('float16')\n",
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 199 entries, 0 to 198\n",
      "Series name: combined_text\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "199 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 80.2 KB\n"
     ]
    }
   ],
   "source": [
    "df = df['combined_text']\n",
    "df.info(memory_usage='deep')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('review_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57c8240fb9f8b833b045e961c68ce448682b5353b732b19b862f259a46a6dd53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
